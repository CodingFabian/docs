{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "409586c9-f2da-4cc4-803e-fe7823228a11",
   "metadata": {},
   "source": [
    "# Run your First Test\n",
    "\n",
    "This is an example of using AutoRedTeam in an SDK style where with only a few lines of code you can determine\n",
    "your LLM agent's vulnerability to malicious attacks and propensity to unintended harms.\n",
    "\n",
    "## Installation\n",
    "\n",
    "First, make sure to have followed the [setup instructions](../../getting-started).\n",
    "Alternately, you can create an fresh environment to install required dependencies, including poetry for dependency management.\n",
    "\n",
    "```bash\n",
    "conda create --name art\n",
    "conda activate art\n",
    "conda install poetry\n",
    "cd autoredteam\n",
    "poetry install\n",
    "```\n",
    "\n",
    "After the above steps, we should be good to go!\n",
    "\n",
    "## Setting up Env\n",
    "Some initial steps are needed allow the tests to work, including getting API keys for the current models and their vendors that are supported.\n",
    "Currently, we support the following model vendors:\n",
    "\n",
    "* [Anyscale](https://docs.endpoints.anyscale.com/guides/authenticate)\n",
    "* [Hugging Face](https://huggingface.co/docs/hub/security-tokens)\n",
    "* [OctoAI](https://docs.octoai.cloud/reference/authentication-for-requests)\n",
    "* [OpenAI](https://platform.openai.com/docs/introduction)\n",
    "* [Replicate](https://replicate.com/docs/reference/http#authentication)\n",
    "\n",
    "You must also store these keys in a `.env` file in the local directory relative to ART so it can be accessed. \n",
    "\n",
    "**Caution**: We highly encourage that you add the `.env` to `.gitignore` and use best practices to keep your personal keys private.\n",
    "\n",
    "An example of what's expected in the `.env` is the following:\n",
    "\n",
    "```text\n",
    "OCTO_API_TOKEN = \"insert your token\"\n",
    "```\n",
    "\n",
    "Once these steps have been taken, you should be set up to run the following code. If everything is successful, you should be able to see a `True` response as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aaf80ff-ea46-4874-af2e-d1f714aa9b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"path/to/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6460f19c-c3b9-411f-9c2c-d98cd47c55b5",
   "metadata": {},
   "source": [
    "## Loading agent\n",
    "Within ART there are a bunch of tests that range from package hallucinations, toxicity detection, stereotype identification, to many others. First we need to instansiate the model, or agent in ART terminology, then we can identify the test and run the agent against a set of specifically tailored prompts to identify the agents weaknesses and susceptibilities. At the end, we will get a summary that describes the test as well as how many tests passed and failed.\n",
    "\n",
    "Let's assume we want to test Mistral-7B-Instruct-v0.1 hosted by OctoAI. To do this, we instantiate a wrapper class for the Octo inference API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f74e23c-3642-473e-80d9-288ac3b2c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoredteam.agents.octo import OctoAPI\n",
    "agent = OctoAPI(name = \"mistral-7b-instruct-fp16\", generations=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9563df-0c9f-4c04-89c1-0b6b9bc6297a",
   "metadata": {},
   "source": [
    "## Selecting Test, Run, and Eval\n",
    "Next we import the test from `autoredteam` and instantiate it, then run it against the agent. Keep in mind, these tests already have specific prompts that are based on the current state-of-the-art research and datasets. Once we select our test, we can run it against the agent and get a summary eval for that test, all in three lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f012e03a-af6c-48cd-bff7-129bc44fe4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "goodside.WhoIsRiley:   0%|                                                                                                   | 0/6 [00:00<?, ?it/s]\n",
      "  0%|                                                                                                                        | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16:   0%|                                                                                       | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16:  50%|███████████████████████████████████████▌                                       | 1/2 [00:01<00:01,  1.49s/it]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16: 100%|███████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.52s/it]\u001b[A\n",
      "goodside.WhoIsRiley:  17%|███████████████▏                                                                           | 1/6 [00:03<00:15,  3.03s/it]\u001b[A\n",
      "  0%|                                                                                                                        | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16:   0%|                                                                                       | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16:  50%|███████████████████████████████████████▌                                       | 1/2 [00:01<00:01,  1.36s/it]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16: 100%|███████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.38s/it]\u001b[A\n",
      "goodside.WhoIsRiley:  33%|██████████████████████████████▎                                                            | 2/6 [00:05<00:11,  2.87s/it]\u001b[A\n",
      "  0%|                                                                                                                        | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16:   0%|                                                                                       | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16:  50%|███████████████████████████████████████▌                                       | 1/2 [00:01<00:01,  1.75s/it]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16: 100%|███████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.72s/it]\u001b[A\n",
      "goodside.WhoIsRiley:  50%|█████████████████████████████████████████████▌                                             | 3/6 [00:09<00:09,  3.14s/it]\u001b[A\n",
      "  0%|                                                                                                                        | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16:   0%|                                                                                       | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16:  50%|███████████████████████████████████████▌                                       | 1/2 [00:01<00:01,  1.55s/it]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16: 100%|███████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.48s/it]\u001b[A\n",
      "goodside.WhoIsRiley:  67%|████████████████████████████████████████████████████████████▋                              | 4/6 [00:12<00:06,  3.08s/it]\u001b[A\n",
      "  0%|                                                                                                                        | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16:   0%|                                                                                       | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16:  50%|███████████████████████████████████████▌                                       | 1/2 [00:01<00:01,  1.08s/it]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16: 100%|███████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.08s/it]\u001b[A\n",
      "goodside.WhoIsRiley:  83%|███████████████████████████████████████████████████████████████████████████▊               | 5/6 [00:14<00:02,  2.75s/it]\u001b[A\n",
      "  0%|                                                                                                                        | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16:   0%|                                                                                       | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16:  50%|███████████████████████████████████████▌                                       | 1/2 [00:01<00:01,  1.10s/it]\u001b[A\n",
      "OctoAI mistral-7b-instruct-fp16: 100%|███████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.10s/it]\u001b[A\n",
      "                                                                                                                                                   \u001b[A\r"
     ]
    }
   ],
   "source": [
    "from autoredteam.tests.goodside import WhoIsRiley\n",
    "test_instance = WhoIsRiley()\n",
    "test_instance.run(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65218ad9-526b-4d92-ad76-0175293bee86",
   "metadata": {},
   "source": [
    "In the outputs, you should see the test that you ran, the test passed and total, and the rate. Congrats, you ran your first test with ART!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
