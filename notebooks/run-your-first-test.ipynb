{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "409586c9-f2da-4cc4-803e-fe7823228a11",
   "metadata": {},
   "source": [
    "# Run your First Test\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/vijilAI/docs/blob/main/notebooks/run-your-first-test.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "This is an example of using ART in an SDK style where with only a few lines of code you can determine\n",
    "your LLM agent's vulnerability to malicious attacks and propensity to unintended harms.\n",
    "\n",
    "<!-- ## Installation\n",
    " -->\n",
    "<!-- Alternatively, you can create an fresh environment to install required dependencies, including poetry for dependency management.\n",
    "\n",
    "```bash\n",
    "conda create --name art\n",
    "conda activate art\n",
    "conda install poetry\n",
    "cd autoredteam\n",
    "poetry install\n",
    "``` -->\n",
    "\n",
    "## Setup\n",
    "First, make sure to have followed the [setup instructions](../../getting-started) to install `autoredteam` and\n",
    "obtain your API keys. As a deminder, we support the following model vendors:\n",
    "\n",
    "* [Anyscale](https://docs.endpoints.anyscale.com/guides/authenticate)\n",
    "* [Hugging Face](https://huggingface.co/docs/hub/security-tokens)\n",
    "* [Mistral](https://docs.mistral.ai/)\n",
    "* [OctoAI](https://docs.octoai.cloud/reference/authentication-for-requests)\n",
    "* [OpenAI](https://platform.openai.com/docs/introduction)\n",
    "* [Replicate](https://replicate.com/docs/reference/http#authentication)\n",
    "* [Together](https://docs.together.ai/docs/inference-rest)\n",
    "\n",
    "There are three ways you can use these keys.\n",
    "\n",
    "1. You can store them in a `.env` locally and load that file here using [python-dotenv](https://pypi.org/project/python-dotenv/).\n",
    "2. You can export the token in bash (`export OCTO_API_TOKEN=''`), then start a notebook environment.\n",
    "3. Or you can simply drop your API key below and proceed (Caution: do NOT share the notebook with your keys in it!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aaf80ff-ea46-4874-af2e-d1f714aa9b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OCTO_API_TOKEN'] = 'your-octo-token'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6460f19c-c3b9-411f-9c2c-d98cd47c55b5",
   "metadata": {},
   "source": [
    "## Loading agent\n",
    "Within ART there are a bunch of tests that range from package hallucinations, toxicity detection, stereotype identification, to many others. First we need to instansiate the model, or agent in ART terminology, then we can identify the test and run the agent against a set of specifically tailored prompts to identify the agents weaknesses and susceptibilities. At the end, we will get a summary that describes the test as well as how many tests passed and failed.\n",
    "\n",
    "Let's assume we want to test Mistral-7B-Instruct-v0.1 hosted by OctoAI. To do this, we instantiate a wrapper class for the Octo inference API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f74e23c-3642-473e-80d9-288ac3b2c938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OctoAI Agent: mistral-7b-instruct-fp16\n"
     ]
    }
   ],
   "source": [
    "# !pip install autoredteam\n",
    "from autoredteam.agents.octo import OctoAPI\n",
    "agent = OctoAPI(name = \"mistral-7b-instruct-fp16\", generations=2)\n",
    "\n",
    "# from autoredteam.agents.anyscale import AnyscaleAPI\n",
    "# agent = AnyscaleAPI(name=\"meta-llama/Llama-2-7b-chat-hf\", generations=2)\n",
    "\n",
    "# from autoredteam.agents.together import TogetherAPI\n",
    "# agent = TogetherAPI(name=\"togethercomputer/falcon-40b\", generations=2)\n",
    "\n",
    "# from autoredteam.agents.mistral import MistralAPI\n",
    "# agent = MistralAPI(name=\"mistral-tiny\", generations=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9563df-0c9f-4c04-89c1-0b6b9bc6297a",
   "metadata": {},
   "source": [
    "## Selecting Test, Run, and Eval\n",
    "Next we import the test from `autoredteam` and instantiate it, then run it against the agent. Keep in mind, these tests already have specific prompts that are based on the current state-of-the-art research and datasets. Once we select our test, we can run it against the agent and get a summary eval for that test, all in three lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f012e03a-af6c-48cd-bff7-129bc44fe4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodside.WhoIsRiley                                                                goodside.RileyIsnt:    9/  12 (  75.0%) passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from autoredteam.tests.goodside import WhoIsRiley\n",
    "test_instance = WhoIsRiley()\n",
    "test_instance.run(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65218ad9-526b-4d92-ad76-0175293bee86",
   "metadata": {},
   "source": [
    "In the outputs, you should see the test that you ran, the test passed and total, and the rate. Congrats, you ran your first test with ART!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
