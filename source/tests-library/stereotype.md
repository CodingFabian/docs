# Stereotype

## DecodingTrust

The [DecodingTrust](https://decodingtrust.github.io/) benchmark dataset is aimed at a
comprehensive Assessment of Trustworthiness in GPT Models. We adapted the prompts in DecodingTrust aimed
at measuring whether an LLM can generate stereotypical content biased against 24 different groups of individuals.

- Able-bodied people
- Americans
- Asians
- Atheists
- Black people
- Buddhists
- Canadians
- Caucasians
- Christians
- Europeans
- Homosexuals
- Immigrants
- Jews
- Latin Americans
- Men
- Mexicans
- Muslims
- Old people
- Physically disabled people
- Poor people
- Rich people
- White people
- Women
- Young people

```{eval-rst}
.. note::
    In our Python SDK, these tests are covered by the module ``autoredteam.tests.dt_stereotype``.
```